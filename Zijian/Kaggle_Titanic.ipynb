{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle titanic project\n",
    "# 0404/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "advance-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense,Dropout,Conv1D,MaxPooling1D,Conv2D,MaxPooling2D,Flatten,LSTM,Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "detected-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "def read_data(train,test):\n",
    "    train_data, test_data = pd.read_csv(train), pd.read_csv(test)\n",
    "    train_data = train_data.drop([\"PassengerId\",\"Name\"],axis=1)\n",
    "    test_data = test_data.drop([\"Name\"],axis=1)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "confirmed-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = read_data(\"/Users/zijianzhao/Downloads/titanic/train.csv\", \"/Users/zijianzhao/Downloads/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "square-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform catogrical features to numerical vectors\n",
    "def to_num(col):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(col)\n",
    "    return le.transform(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "controlled-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert catogrical features to numerical vectors\n",
    "train[\"Sex\"] = to_num(train[\"Sex\"])\n",
    "train[\"Ticket\"] = to_num(train[\"Ticket\"])\n",
    "train[\"Cabin\"] = to_num(train[\"Cabin\"])\n",
    "\n",
    "test[\"Sex\"] = to_num(test[\"Sex\"])\n",
    "test[\"Ticket\"] = to_num(test[\"Ticket\"])\n",
    "test[\"Cabin\"] = to_num(test[\"Cabin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "champion-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features with large interval\n",
    "def norm(col):\n",
    "    col = col.values.reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(col)\n",
    "    return scaler.transform(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "suited-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"] = norm(train[\"Age\"])\n",
    "train[\"Fare\"] = norm(train[\"Fare\"])\n",
    "train[\"Ticket\"] = norm(train[\"Ticket\"])\n",
    "train[\"Cabin\"] = norm(train[\"Cabin\"])\n",
    "\n",
    "test[\"Age\"] = norm(test[\"Age\"])\n",
    "test[\"Fare\"] = norm(test[\"Fare\"])\n",
    "test[\"Ticket\"] = norm(test[\"Ticket\"])\n",
    "test[\"Cabin\"] = norm(test[\"Cabin\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "chemical-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train, columns = [\"Pclass\", \"Embarked\",\"SibSp\"])\n",
    "test_data = pd.get_dummies(test, columns = [\"Pclass\", \"Embarked\",\"SibSp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "weekly-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validate_data = train_test_split(train_data,test_size=0.15)\n",
    "train_Y, train_X = train_data[\"Survived\"], train_data.drop(\"Survived\",axis=1)\n",
    "validate_Y, validate_X = validate_data[\"Survived\"], validate_data.drop(\"Survived\",axis=1)\n",
    "train = xgb.DMatrix(train_X, label=train_Y, enable_categorical=True)\n",
    "validate = xgb.DMatrix(validate_X, label=validate_Y, enable_categorical=True)\n",
    "test_id = test_data[\"PassengerId\"]\n",
    "test = test_data.drop(\"PassengerId\",axis=1)\n",
    "test = xgb.DMatrix(test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "civilian-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "detailed-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 10,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    #'eval_metric': 'merror'\n",
    "}\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "dress-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "associate-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "varying-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "anticipated-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "analyzed-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432835820895522"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validate_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "american-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "political-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(sub,columns=[\"Survived\"])\n",
    "sub = pd.concat([pd.DataFrame(test_id),sub.astype(int)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "operational-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"predictions.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "divided-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
